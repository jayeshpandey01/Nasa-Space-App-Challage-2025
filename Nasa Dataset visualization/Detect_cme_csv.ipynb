{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_2152\\1197466339.py:1: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  epam_data = pd.read_csv('csv_file/ace_epam_data.csv')\n"
     ]
    }
   ],
   "source": [
    "epam_data = pd.read_csv('csv_file/ace_epam_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>HHMM</th>\n",
       "      <th>Julian_Day</th>\n",
       "      <th>Seconds_of_Day</th>\n",
       "      <th>Electron_S</th>\n",
       "      <th>Electron_38-53</th>\n",
       "      <th>Electron_175-315</th>\n",
       "      <th>Proton_S</th>\n",
       "      <th>Proton_47-65</th>\n",
       "      <th>Proton_112-187</th>\n",
       "      <th>Proton_310-580</th>\n",
       "      <th>Proton_761-1220</th>\n",
       "      <th>Proton_1060-1910</th>\n",
       "      <th>Anisotropy_Ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>129.00</td>\n",
       "      <td>9.200</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2001</td>\n",
       "      <td>20010807_ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52128.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>122.00</td>\n",
       "      <td>7.410</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2001</td>\n",
       "      <td>20010807_ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52128.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>6.650</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2001</td>\n",
       "      <td>20010807_ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>52128.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>7.180</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2001</td>\n",
       "      <td>20010807_ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52128.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>131.00</td>\n",
       "      <td>7.670</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2001</td>\n",
       "      <td>20010807_ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512487</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>60850.0</td>\n",
       "      <td>55200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1.170</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512488</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>60850.0</td>\n",
       "      <td>55500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.320</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512489</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>60850.0</td>\n",
       "      <td>55800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>9.73</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512490</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>60850.0</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>7.91</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512491</th>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>60850.0</td>\n",
       "      <td>56400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ace_epam_5m.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2512492 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             YR   MO    DA    HHMM  Julian_Day  Seconds_of_Day  Electron_S  \\\n",
       "0        2001.0  8.0   7.0     0.0     52128.0             0.0         0.0   \n",
       "1        2001.0  8.0   7.0     5.0     52128.0           300.0         0.0   \n",
       "2        2001.0  8.0   7.0    10.0     52128.0           600.0         0.0   \n",
       "3        2001.0  8.0   7.0    15.0     52128.0           900.0         0.0   \n",
       "4        2001.0  8.0   7.0    20.0     52128.0          1200.0         0.0   \n",
       "...         ...  ...   ...     ...         ...             ...         ...   \n",
       "2512487  2025.0  6.0  24.0  1520.0     60850.0         55200.0         0.0   \n",
       "2512488  2025.0  6.0  24.0  1525.0     60850.0         55500.0         0.0   \n",
       "2512489  2025.0  6.0  24.0  1530.0     60850.0         55800.0         0.0   \n",
       "2512490  2025.0  6.0  24.0  1535.0     60850.0         56100.0         0.0   \n",
       "2512491  2025.0  6.0  24.0  1540.0     60850.0         56400.0         0.0   \n",
       "\n",
       "         Electron_38-53  Electron_175-315  Proton_S  Proton_47-65  \\\n",
       "0                 722.0              16.0       0.0        1280.0   \n",
       "1                 732.0              19.6       0.0        1220.0   \n",
       "2                 694.0              11.6       0.0        1130.0   \n",
       "3                 704.0              14.7       0.0        1210.0   \n",
       "4                 797.0              13.4       0.0        1560.0   \n",
       "...                 ...               ...       ...           ...   \n",
       "2512487          1470.0              13.7       0.0        2740.0   \n",
       "2512488          1430.0              11.5       0.0        2630.0   \n",
       "2512489          1690.0              10.2       0.0        2920.0   \n",
       "2512490          1430.0              14.1       0.0        2760.0   \n",
       "2512491          1390.0              14.9       0.0        2570.0   \n",
       "\n",
       "         Proton_112-187  Proton_310-580  Proton_761-1220  Proton_1060-1910  \\\n",
       "0                129.00           9.200            0.954             0.219   \n",
       "1                122.00           7.410            0.786             0.234   \n",
       "2                123.00           6.650            0.633             0.193   \n",
       "3                120.00           7.180            0.946             0.252   \n",
       "4                131.00           7.670            0.889             0.321   \n",
       "...                 ...             ...              ...               ...   \n",
       "2512487            9.02           1.170            0.398             0.154   \n",
       "2512488            6.29           1.320            0.462             0.143   \n",
       "2512489            9.73           0.833            0.202             0.194   \n",
       "2512490            7.91           1.200            0.359             0.187   \n",
       "2512491            8.56           1.180            0.590             0.203   \n",
       "\n",
       "         Anisotropy_Ratio     year                      file  \n",
       "0                    0.47     2001  20010807_ace_epam_5m.txt  \n",
       "1                   -1.00     2001  20010807_ace_epam_5m.txt  \n",
       "2                    0.90     2001  20010807_ace_epam_5m.txt  \n",
       "3                    0.68     2001  20010807_ace_epam_5m.txt  \n",
       "4                    1.38     2001  20010807_ace_epam_5m.txt  \n",
       "...                   ...      ...                       ...  \n",
       "2512487             -1.00  unknown           ace_epam_5m.txt  \n",
       "2512488             -1.00  unknown           ace_epam_5m.txt  \n",
       "2512489             -1.00  unknown           ace_epam_5m.txt  \n",
       "2512490             -1.00  unknown           ace_epam_5m.txt  \n",
       "2512491             -1.00  unknown           ace_epam_5m.txt  \n",
       "\n",
       "[2512492 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YR                       0\n",
       "MO                       0\n",
       "DA                       0\n",
       "HHMM                     0\n",
       "Julian_Day               0\n",
       "Seconds_of_Day           0\n",
       "Electron_S               0\n",
       "Electron_38-53      157500\n",
       "Electron_175-315    162249\n",
       "Proton_S                 0\n",
       "Proton_47-65        196353\n",
       "Proton_112-187      197502\n",
       "Proton_310-580      193515\n",
       "Proton_761-1220     163474\n",
       "Proton_1060-1910    162975\n",
       "Anisotropy_Ratio        14\n",
       "year                     0\n",
       "file                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epam_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_2152\\1437388060.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mag_data = pd.read_csv('csv_file/ace_mag_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YR                     0\n",
       "MO                     0\n",
       "DA                     0\n",
       "HHMM                   0\n",
       "Julian_Day             0\n",
       "Seconds_of_Day         0\n",
       "S                      0\n",
       "Bx                645780\n",
       "By                645780\n",
       "Bz                645780\n",
       "Bt                645780\n",
       "Latitude          645780\n",
       "Longitude         645780\n",
       "year                   0\n",
       "file                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_data = pd.read_csv('csv_file/ace_mag_data.csv')\n",
    "mag_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_2152\\4078888639.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sis_data = pd.read_csv('csv_file/ace_sis_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YR                     0\n",
       "MO                     0\n",
       "DA                     0\n",
       "HHMM                   0\n",
       "Julian_Day             0\n",
       "Seconds_of_Day         0\n",
       "S_10MeV                0\n",
       "Proton_>10MeV     154854\n",
       "S_30MeV                0\n",
       "Proton_>30MeV     154852\n",
       "year                   0\n",
       "file                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sis_data = pd.read_csv('csv_file/ace_sis_data.csv')\n",
    "sis_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_2152\\4283189267.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  swepam_data = pd.read_csv('csv_file/ace_swepam_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YR                       0\n",
       "MO                       0\n",
       "DA                       0\n",
       "HHMM                     0\n",
       "Julian_Day               0\n",
       "Seconds_of_Day           0\n",
       "S                        0\n",
       "Proton_Density     1155078\n",
       "Bulk_Speed         1188978\n",
       "Ion_Temperature    1364206\n",
       "year                     0\n",
       "file                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swepam_data = pd.read_csv('csv_file/ace_swepam_data.csv')\n",
    "swepam_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Proton_Density\n",
       "1.6      249706\n",
       "1.8      248457\n",
       "1.9      247742\n",
       "1.7      247695\n",
       "1.5      247064\n",
       "          ...  \n",
       "176.6         1\n",
       "91.2          1\n",
       "165.7         1\n",
       "168.4         1\n",
       "191.6         1\n",
       "Name: count, Length: 1575, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swepam_data['Proton_Density'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "swepam_data_drop = swepam_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YR                 0\n",
       "MO                 0\n",
       "DA                 0\n",
       "HHMM               0\n",
       "Julian_Day         0\n",
       "Seconds_of_Day     0\n",
       "S                  0\n",
       "Proton_Density     0\n",
       "Bulk_Speed         0\n",
       "Ion_Temperature    0\n",
       "year               0\n",
       "file               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swepam_data_drop.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont drop any rows which have into the swepam_data_drop variable and others are dropes\n",
    "# epam_data_drop = epam_data.loc[swepam_data_drop.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cudf-cu11\n",
      "  Downloading cudf_cu11-25.6.0.tar.gz (2.7 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [72 lines of output]\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp310-cp310-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp310-cp310-manylinux_2_24_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp310-cp310-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp310-cp310-manylinux_2_28_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp310-cp310-manylinux_2_24_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp310-cp310-manylinux_2_28_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp311-cp311-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp311-cp311-manylinux_2_24_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp311-cp311-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp311-cp311-manylinux_2_28_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp311-cp311-manylinux_2_24_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp311-cp311-manylinux_2_28_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp312-cp312-manylinux_2_28_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp312-cp312-manylinux_2_24_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp312-cp312-manylinux_2_24_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp312-cp312-manylinux_2_28_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp313-cp313-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp313-cp313-manylinux_2_24_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp313-cp313-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl against tag cp313-cp313-manylinux_2_28_aarch64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp313-cp313-manylinux_2_24_x86_64\n",
      "      INFO:wheel-stub:Testing wheel cudf_cu11-25.6.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl against tag cp313-cp313-manylinux_2_28_x86_64\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\wheel.py\", line 249, in download_wheel\n",
      "          return download_manual(wheel_directory, distribution, version, config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\wheel.py\", line 185, in download_manual\n",
      "          raise RuntimeError(f\"Didn't find wheel for {distribution} {version}\")\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\wheel.py\", line 249, in download_wheel\n",
      "          return download_manual(wheel_directory, distribution, version, config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\wheel.py\", line 185, in download_manual\n",
      "          raise RuntimeError(f\"Didn't find wheel for {distribution} {version}\")\n",
      "      RuntimeError: Didn't find wheel for cudf-cu11 25.6.0\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 152, in prepare_metadata_for_build_wheel\n",
      "          whl_basename = backend.build_wheel(metadata_directory, config_settings)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\buildapi.py\", line 29, in build_wheel\n",
      "          return download_wheel(pathlib.Path(wheel_directory), config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\wheel.py\", line 251, in download_wheel\n",
      "          report_install_failure(distribution, version, config, exception_context)\n",
      "        File \"C:\\Users\\harsh\\AppData\\Local\\Temp\\pip-build-env-84uggu_x\\overlay\\Lib\\site-packages\\wheel_stub\\error.py\", line 67, in report_install_failure\n",
      "          raise InstallFailedError(\n",
      "      wheel_stub.error.InstallFailedError:\n",
      "      *******************************************************************************\n",
      "      \n",
      "      The installation of cudf-cu11 for version 25.6.0 failed.\n",
      "      \n",
      "      This is a special placeholder package which downloads a real wheel package\n",
      "      from https://pypi.nvidia.com/. If https://pypi.nvidia.com/ is not reachable, we\n",
      "      cannot download the real wheel file to install.\n",
      "      \n",
      "      You might try installing this package via\n",
      "      ```\n",
      "      $ pip install --extra-index-url https://pypi.nvidia.com/ cudf-cu11\n",
      "      ```\n",
      "      \n",
      "      Here is some debug information about your platform to include in any bug\n",
      "      report:\n",
      "      \n",
      "      Python Version: CPython 3.11.9\n",
      "      Operating System: Windows 10\n",
      "      CPU Architecture: AMD64\n",
      "      Driver Version: 561.19\n",
      "      CUDA Version: 12.6\n",
      "      \n",
      "      *******************************************************************************\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cudf-cu11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcudf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1. Point to your CSV files\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#    Assuming they’re named EPAM.csv, MAG.csv, SIS.csv, SWICS.csv\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import glob\n",
    "\n",
    "# 1. Point to your CSV files\n",
    "#    Assuming they’re named EPAM.csv, MAG.csv, SIS.csv, SWICS.csv\n",
    "csv_files = {\n",
    "    \"epam\":  \"csv_file/ace_epam_data.csv\",\n",
    "    \"mag\":   \"csv_file/ace_mag_data.csv\",\n",
    "    \"sis\":   \"csv_file/ace_sis_data.csv\",\n",
    "    \"swics\": \"csv_file/ace_swepam_data.csv\",\n",
    "}\n",
    "\n",
    "# 2. Read each into a cuDF DataFrame\n",
    "df_epam  = cudf.read_csv(csv_files[\"epam\"])\n",
    "df_mag   = cudf.read_csv(csv_files[\"mag\"])\n",
    "df_sis   = cudf.read_csv(csv_files[\"sis\"])\n",
    "df_swics = cudf.read_csv(csv_files[\"swics\"])\n",
    "\n",
    "# 3. Parse and set a GPU‐accelerated datetime index\n",
    "def to_datetime_gpu(df):\n",
    "    # assuming columns YR, MO, DA, HHMM\n",
    "    # HHMM is integer like 1305 == 13:05\n",
    "    df[\"hour\"]   = (df.HHMM // 100).astype(\"int8\")\n",
    "    df[\"minute\"] = (df.HHMM % 100).astype(\"int8\")\n",
    "    df[\"date_str\"] = (\n",
    "        df.YR.astype(\"str\") + \"-\" +\n",
    "        df.MO.astype(\"str\").str.zfill(2) + \"-\" +\n",
    "        df.DA.astype(\"str\").str.zfill(2) + \" \" +\n",
    "        df.hour.astype(\"str\").str.zfill(2) + \":\" +\n",
    "        df.minute.astype(\"str\").str.zfill(2)\n",
    "    )\n",
    "    # GPU parse\n",
    "    df[\"datetime\"] = cudf.to_datetime(df.date_str)\n",
    "    return df.set_index(\"datetime\").drop(columns=[\"hour\",\"minute\",\"date_str\"])\n",
    "\n",
    "df_epam  = to_datetime_gpu(df_epam)\n",
    "df_mag   = to_datetime_gpu(df_mag)\n",
    "df_sis   = to_datetime_gpu(df_sis)\n",
    "df_swics = to_datetime_gpu(df_swics)\n",
    "\n",
    "# 4. Handle nulls on each stream before merging\n",
    "#    Here we forward‐ and backward‐fill, then fill any remaining with column means\n",
    "for df in (df_epam, df_mag, df_sis, df_swics):\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    df.fillna(method=\"bfill\", inplace=True)\n",
    "    # if still null (e.g. entire column), fill with mean\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# 5. (Optional) Resample high‑rate MAG/SWICS to 1‑minute and interpolate\n",
    "df_mag_1min   = df_mag.resample(\"1T\").mean().interpolate()\n",
    "df_swics_1min = df_swics.resample(\"1T\").mean().interpolate()\n",
    "\n",
    "# 6. Merge all four on the datetime index\n",
    "df_all = (\n",
    "    df_epam[[\"Electron_S\",\"Electron_38-53\",\"Electron_175-315\",\"Proton_47-65\",\"Proton_112-187\"]]\n",
    "    .join(df_mag_1min,   how=\"inner\")\n",
    "    .join(df_sis[[\"S_10MeV\",\"Proton_>10MeV\",\"S_30MeV\",\"Proton_>30MeV\"]], how=\"inner\")\n",
    "    .join(df_swics_1min, how=\"inner\")\n",
    ")\n",
    "\n",
    "print(f\"Final shape: {df_all.shape}\")\n",
    "print(\"Null counts per column:\")\n",
    "print(df_all.isnull().sum())\n",
    "\n",
    "# 7. From here you can run your CME detection pipeline on df_all, all in GPU memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CME Dectection pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcudf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1. Point to your CSV files\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#    Assuming they’re named EPAM.csv, MAG.csv, SIS.csv, SWICS.csv\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import glob\n",
    "\n",
    "# 1. Point to your CSV files\n",
    "#    Assuming they’re named EPAM.csv, MAG.csv, SIS.csv, SWICS.csv\n",
    "csv_files = {\n",
    "    \"epam\":  \"csv_file/ace_epam_data.csv\",\n",
    "    \"mag\":   \"csv_file/ace_mag_data.csv\",\n",
    "    \"sis\":   \"csv_file/ace_sis_data.csv\",\n",
    "    \"swics\": \"csv_file/ace_swepam_data.csv\",\n",
    "}\n",
    "\n",
    "# 2. Read each into a cuDF DataFrame\n",
    "df_epam  = cudf.read_csv(csv_files[\"epam\"])\n",
    "df_mag   = cudf.read_csv(csv_files[\"mag\"])\n",
    "df_sis   = cudf.read_csv(csv_files[\"sis\"])\n",
    "df_swics = cudf.read_csv(csv_files[\"swics\"])\n",
    "\n",
    "# 3. Parse and set a GPU‐accelerated datetime index\n",
    "def to_datetime_gpu(df):\n",
    "    # assuming columns YR, MO, DA, HHMM\n",
    "    # HHMM is integer like 1305 == 13:05\n",
    "    df[\"hour\"]   = (df.HHMM // 100).astype(\"int8\")\n",
    "    df[\"minute\"] = (df.HHMM % 100).astype(\"int8\")\n",
    "    df[\"date_str\"] = (\n",
    "        df.YR.astype(\"str\") + \"-\" +\n",
    "        df.MO.astype(\"str\").str.zfill(2) + \"-\" +\n",
    "        df.DA.astype(\"str\").str.zfill(2) + \" \" +\n",
    "        df.hour.astype(\"str\").str.zfill(2) + \":\" +\n",
    "        df.minute.astype(\"str\").str.zfill(2)\n",
    "    )\n",
    "    # GPU parse\n",
    "    df[\"datetime\"] = cudf.to_datetime(df.date_str)\n",
    "    return df.set_index(\"datetime\").drop(columns=[\"hour\",\"minute\",\"date_str\"])\n",
    "\n",
    "df_epam  = to_datetime_gpu(df_epam)\n",
    "df_mag   = to_datetime_gpu(df_mag)\n",
    "df_sis   = to_datetime_gpu(df_sis)\n",
    "df_swics = to_datetime_gpu(df_swics)\n",
    "\n",
    "# 4. Handle nulls on each stream before merging\n",
    "#    Here we forward‐ and backward‐fill, then fill any remaining with column means\n",
    "for df in (df_epam, df_mag, df_sis, df_swics):\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    df.fillna(method=\"bfill\", inplace=True)\n",
    "    # if still null (e.g. entire column), fill with mean\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# 5. (Optional) Resample high‑rate MAG/SWICS to 1‑minute and interpolate\n",
    "df_mag_1min   = df_mag.resample(\"1T\").mean().interpolate()\n",
    "df_swics_1min = df_swics.resample(\"1T\").mean().interpolate()\n",
    "\n",
    "# 6. Merge all four on the datetime index\n",
    "df_all = (\n",
    "    df_epam[[\"Electron_S\",\"Electron_38-53\",\"Electron_175-315\",\"Proton_47-65\",\"Proton_112-187\"]]\n",
    "    .join(df_mag_1min,   how=\"inner\")\n",
    "    .join(df_sis[[\"S_10MeV\",\"Proton_>10MeV\",\"S_30MeV\",\"Proton_>30MeV\"]], how=\"inner\")\n",
    "    .join(df_swics_1min, how=\"inner\")\n",
    ")\n",
    "\n",
    "print(f\"Final shape: {df_all.shape}\")\n",
    "print(\"Null counts per column:\")\n",
    "print(df_all.isnull().sum())\n",
    "\n",
    "# 7. From here you can run your CME detection pipeline on df_all, all in GPU memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_23888\\2702617318.py:6: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_23888\\2702617318.py:6: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_23888\\2702617318.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_23888\\2702617318.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 95.8 MiB for an array with shape (12562823,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m df_mag   = load_and_index(\u001b[33m\"\u001b[39m\u001b[33mcsv_file/ace_mag_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m df_sis   = load_and_index(\u001b[33m\"\u001b[39m\u001b[33mcsv_file/ace_sis_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m df_swics = \u001b[43mload_and_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsv_file/ace_swepam_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# === 2. Handle Nulls ===\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m [df_epam, df_mag, df_sis, df_swics]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mload_and_index\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     15\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mminute\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mHHMM\u001b[39m\u001b[33m\"\u001b[39m] % \u001b[32m100\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Format datetime correctly\u001b[39;00m\n\u001b[32m     18\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\n\u001b[32m     19\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mYR\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.zfill(\u001b[32m4\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m     20\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mMO\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.zfill(\u001b[32m2\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m     21\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mDA\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.zfill(\u001b[32m2\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhour\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m + \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m     23\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mminute\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.zfill(\u001b[32m2\u001b[39m),\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m df = df.set_index(\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mYR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMO\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHHMM\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mminute\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:136\u001b[39m, in \u001b[36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m     msg = (\n\u001b[32m    132\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with values of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minferred dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:1793\u001b[39m, in \u001b[36mStringMethods.zfill\u001b[39m\u001b[34m(self, width)\u001b[39m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m   1792\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: x.zfill(width)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:78\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_map\u001b[39m\u001b[34m(self, f, na_value, dtype, convert)\u001b[39m\n\u001b[32m     76\u001b[39m map_convert = convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(mask)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     result = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[32m     82\u001b[39m     p_err = (\n\u001b[32m     83\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m((takes)|(missing)) (?(2)from \u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ to )?\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?(3)required )positional arguments?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2884\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer_mask\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2516\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_objects\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 95.8 MiB for an array with shape (12562823,) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === 1. Load and Parse CSVs ===\n",
    "def load_and_index(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Ensure all columns are integers (no floats like 2001.0)\n",
    "    df[\"YR\"] = df[\"YR\"].astype(int)\n",
    "    df[\"MO\"] = df[\"MO\"].astype(int)\n",
    "    df[\"DA\"] = df[\"DA\"].astype(int)\n",
    "    df[\"HHMM\"] = df[\"HHMM\"].astype(int)\n",
    "\n",
    "    df[\"hour\"] = df[\"HHMM\"] // 100\n",
    "    df[\"minute\"] = df[\"HHMM\"] % 100\n",
    "\n",
    "    # Format datetime correctly\n",
    "    df[\"datetime\"] = pd.to_datetime(\n",
    "        df[\"YR\"].astype(str).str.zfill(4) + \"-\" +\n",
    "        df[\"MO\"].astype(str).str.zfill(2) + \"-\" +\n",
    "        df[\"DA\"].astype(str).str.zfill(2) + \" \" +\n",
    "        df[\"hour\"].astype(str).str.zfill(2) + \":\" +\n",
    "        df[\"minute\"].astype(str).str.zfill(2),\n",
    "        format=\"%Y-%m-%d %H:%M\"\n",
    "    )\n",
    "\n",
    "    df = df.set_index(\"datetime\")\n",
    "    return df.drop(columns=[\"YR\", \"MO\", \"DA\", \"HHMM\", \"hour\", \"minute\"])\n",
    "\n",
    "\n",
    "csv_files = {\n",
    "    \"epam\":  \"csv_file/ace_epam_data.csv\",\n",
    "    \"mag\":   \"csv_file/ace_mag_data.csv\",\n",
    "    \"sis\":   \"csv_file/ace_sis_data.csv\",\n",
    "    \"swics\": \"csv_file/ace_swepam_data.csv\",\n",
    "}\n",
    "\n",
    "# Replace with your actual CSV file paths\n",
    "df_epam  = load_and_index(\"csv_file/ace_epam_data.csv\")\n",
    "df_mag   = load_and_index(\"csv_file/ace_mag_data.csv\")\n",
    "df_sis   = load_and_index(\"csv_file/ace_sis_data.csv\")\n",
    "df_swics = load_and_index(\"csv_file/ace_swepam_data.csv\")\n",
    "\n",
    "# === 2. Handle Nulls ===\n",
    "for df in [df_epam, df_mag, df_sis, df_swics]:\n",
    "    df.ffill(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# === 3. Resample MAG & SWICS ===\n",
    "df_mag = df_mag.resample(\"1T\").mean().interpolate()\n",
    "df_swics = df_swics.resample(\"1T\").mean().interpolate()\n",
    "\n",
    "# === 4. Merge Data ===\n",
    "df = (\n",
    "    df_epam[[\"Electron_38-53\", \"Electron_175-315\", \"Proton_47-65\", \"Proton_112-187\"]]\n",
    "    .join(df_mag[[\"Bx\", \"By\", \"Bz\"]], how=\"inner\")\n",
    "    .join(df_sis[[\"Proton_>10MeV\"]], how=\"inner\")\n",
    "    .join(df_swics[[\"Proton_Density\", \"Bulk_Speed\", \"Ion_Temperature\"]], how=\"inner\")\n",
    ")\n",
    "\n",
    "# === 5. Feature Engineering ===\n",
    "df[\"Bt\"] = np.sqrt(df[\"Bx\"]**2 + df[\"By\"]**2 + df[\"Bz\"]**2)\n",
    "df[\"T_expected\"] = 0.031 * df[\"Bulk_Speed\"]**1.6\n",
    "df[\"Temp_Ratio\"] = df[\"Ion_Temperature\"] / df[\"T_expected\"]\n",
    "\n",
    "# === 6. Detect Shocks ===\n",
    "def detect_shocks(df, window=10, dV_thresh=70, dNp_thresh=5, dBt_thresh=4):\n",
    "    V_diff  = df[\"Bulk_Speed\"].diff(periods=window)\n",
    "    Np_diff = df[\"Proton_Density\"].diff(periods=window)\n",
    "    Bt_diff = df[\"Bt\"].diff(periods=window)\n",
    "\n",
    "    mask = (V_diff > dV_thresh) & (Np_diff > dNp_thresh) & (Bt_diff > dBt_thresh)\n",
    "    shock_times = df.index[mask.fillna(False)]\n",
    "    return shock_times\n",
    "\n",
    "shocks = detect_shocks(df)\n",
    "\n",
    "print(\"\\n🔍 Detected CME Shock Times:\")\n",
    "for t in shocks:\n",
    "    print(t)\n",
    "\n",
    "# === 7. (Optional) Magnetic Cloud Detection ===\n",
    "def detect_mag_clouds(df, shocks, hours=24):\n",
    "    clouds = []\n",
    "    for t in shocks:\n",
    "        window = df.loc[t : t + pd.Timedelta(hours=hours)]\n",
    "        if len(window) == 0:\n",
    "            continue\n",
    "        low_temp = (window[\"Temp_Ratio\"] < 0.5).sum() > 0.75 * len(window)\n",
    "        low_beta = (window[\"Proton_Density\"] * window[\"Ion_Temperature\"] < 2 * (window[\"Bt\"]**2)).sum() > 0.75 * len(window)\n",
    "        if low_temp and low_beta:\n",
    "            clouds.append((t, t + pd.Timedelta(hours=hours)))\n",
    "    return clouds\n",
    "\n",
    "clouds = detect_mag_clouds(df, shocks)\n",
    "\n",
    "print(\"\\n🌩️ Magnetic Cloud Signatures Detected:\")\n",
    "for start, end in clouds:\n",
    "    print(f\"{start} → {end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1874\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1873\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m     res_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:850\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    848\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    852\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:871\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    870\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m     res = extract_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2380\u001b[39m, in \u001b[36mGroupBy.mean.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2378\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._cython_agg_general(\n\u001b[32m   2379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2380\u001b[39m         alt=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2381\u001b[39m         numeric_only=numeric_only,\n\u001b[32m   2382\u001b[39m     )\n\u001b[32m   2383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6221\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6213\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6215\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6219\u001b[39m     **kwargs,\n\u001b[32m   6220\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11984\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11977\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  11978\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  11979\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11982\u001b[39m     **kwargs,\n\u001b[32m  11983\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m11984\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  11985\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  11986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11941\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11939\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m11941\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  11942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  11943\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6129\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6126\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6128\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1693\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1692\u001b[39m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1693\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert string \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1694\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert string '2025' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m     df.fillna(df.mean(numeric_only=\u001b[38;5;28;01mTrue\u001b[39;00m), inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# ✅ 4. Resample MAG/SWICS to 1-min\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df_mag = \u001b[43mdf_mag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1T\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.interpolate()\n\u001b[32m     46\u001b[39m df_swics = df_swics.resample(\u001b[33m\"\u001b[39m\u001b[33m1T\u001b[39m\u001b[33m\"\u001b[39m).mean().interpolate()\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ✅ 5. Merge everything\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1342\u001b[39m, in \u001b[36mResampler.mean\u001b[39m\u001b[34m(self, numeric_only, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m maybe_warn_args_and_kwargs(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs)\n\u001b[32m   1341\u001b[39m nv.validate_resampler_func(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_downsample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1728\u001b[39m, in \u001b[36mDatetimeIndexResampler._downsample\u001b[39m\u001b[34m(self, how, **kwargs)\u001b[39m\n\u001b[32m   1725\u001b[39m \u001b[38;5;66;03m# we are downsampling\u001b[39;00m\n\u001b[32m   1726\u001b[39m \u001b[38;5;66;03m# we want to call the actual grouper method here\u001b[39;00m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axis == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1728\u001b[39m     result = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrouper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1730\u001b[39m     \u001b[38;5;66;03m# test_resample_axis1\u001b[39;00m\n\u001b[32m   1731\u001b[39m     result = obj.T.groupby(\u001b[38;5;28mself\u001b[39m.grouper).aggregate(how, **kwargs).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1445\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1442\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1444\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1447\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:172\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    169\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m.kwargs\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_dict_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:586\u001b[39m, in \u001b[36mApply.apply_str\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    585\u001b[39m             \u001b[38;5;28mself\u001b[39m.kwargs[\u001b[33m\"\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.axis\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:669\u001b[39m, in \u001b[36mApply._apply_str\u001b[39m\u001b[34m(self, obj, func, *args, **kwargs)\u001b[39m\n\u001b[32m    667\u001b[39m f = \u001b[38;5;28mgetattr\u001b[39m(obj, func)\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2378\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2372\u001b[39m         grouped_mean,\n\u001b[32m   2373\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2374\u001b[39m         engine_kwargs,\n\u001b[32m   2375\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2376\u001b[39m     )\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   1926\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1929\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1930\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   1931\u001b[39m out = \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1428\u001b[39m, in \u001b[36mBlockManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blk.is_object:\n\u001b[32m   1425\u001b[39m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[32m   1426\u001b[39m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk._split():\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         applied = \u001b[43msb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m         result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:366\u001b[39m, in \u001b[36mBlock.apply\u001b[39m\u001b[34m(self, func, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, **kwargs) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    362\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    one\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     result = maybe_coerce_values(result)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._split_op_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1926\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1926\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1878\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1876\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1877\u001b[39m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1878\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ser.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m   1881\u001b[39m     res_values = res_values.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 1. Memory-Efficient Loader\n",
    "def load_and_index_in_chunks(filepath, chunk_size=500_000):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "        chunk = chunk.dropna(subset=[\"YR\", \"MO\", \"DA\", \"HHMM\"])  # ensure datetime columns are present\n",
    "        chunk[\"YR\"] = chunk[\"YR\"].astype(int)\n",
    "        chunk[\"MO\"] = chunk[\"MO\"].astype(int)\n",
    "        chunk[\"DA\"] = chunk[\"DA\"].astype(int)\n",
    "        chunk[\"HHMM\"] = chunk[\"HHMM\"].astype(int)\n",
    "\n",
    "        chunk[\"hour\"] = chunk[\"HHMM\"] // 100\n",
    "        chunk[\"minute\"] = chunk[\"HHMM\"] % 100\n",
    "\n",
    "        # Use dict format for datetime parsing (fastest)\n",
    "        chunk[\"datetime\"] = pd.to_datetime({\n",
    "            \"year\": chunk[\"YR\"],\n",
    "            \"month\": chunk[\"MO\"],\n",
    "            \"day\": chunk[\"DA\"],\n",
    "            \"hour\": chunk[\"hour\"],\n",
    "            \"minute\": chunk[\"minute\"]\n",
    "        })\n",
    "\n",
    "        chunk.set_index(\"datetime\", inplace=True)\n",
    "        chunk.drop(columns=[\"YR\", \"MO\", \"DA\", \"HHMM\", \"hour\", \"minute\"], inplace=True)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return pd.concat(chunks)\n",
    "\n",
    "# ✅ 2. Load files (adjust path as needed)\n",
    "df_epam  = load_and_index_in_chunks(\"csv_file/ace_epam_data.csv\")\n",
    "df_mag   = load_and_index_in_chunks(\"csv_file/ace_mag_data.csv\")\n",
    "df_sis   = load_and_index_in_chunks(\"csv_file/ace_sis_data.csv\")\n",
    "df_swics = load_and_index_in_chunks(\"csv_file/ace_swepam_data.csv\")\n",
    "\n",
    "# ✅ 3. Fill nulls\n",
    "for df in [df_epam, df_mag, df_sis, df_swics]:\n",
    "    df.ffill(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# ✅ 4. Resample MAG/SWICS to 1-min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 863. MiB for an array with shape (12566400, 9) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m df_mag_numeric = df_mag.select_dtypes(include=[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m df_swics_numeric = df_swics.select_dtypes(include=[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_mag = \u001b[43mdf_mag_numeric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1T\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.interpolate()\n\u001b[32m      6\u001b[39m df_swics = df_swics_numeric.resample(\u001b[33m\"\u001b[39m\u001b[33m1T\u001b[39m\u001b[33m\"\u001b[39m).mean().interpolate()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ✅ 5. Merge everything\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1342\u001b[39m, in \u001b[36mResampler.mean\u001b[39m\u001b[34m(self, numeric_only, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m maybe_warn_args_and_kwargs(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs)\n\u001b[32m   1341\u001b[39m nv.validate_resampler_func(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_downsample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1728\u001b[39m, in \u001b[36mDatetimeIndexResampler._downsample\u001b[39m\u001b[34m(self, how, **kwargs)\u001b[39m\n\u001b[32m   1725\u001b[39m \u001b[38;5;66;03m# we are downsampling\u001b[39;00m\n\u001b[32m   1726\u001b[39m \u001b[38;5;66;03m# we want to call the actual grouper method here\u001b[39;00m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axis == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1728\u001b[39m     result = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrouper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1730\u001b[39m     \u001b[38;5;66;03m# test_resample_axis1\u001b[39;00m\n\u001b[32m   1731\u001b[39m     result = obj.T.groupby(\u001b[38;5;28mself\u001b[39m.grouper).aggregate(how, **kwargs).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1445\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1442\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1444\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1447\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:172\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    169\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m.kwargs\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_dict_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:586\u001b[39m, in \u001b[36mApply.apply_str\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    585\u001b[39m             \u001b[38;5;28mself\u001b[39m.kwargs[\u001b[33m\"\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.axis\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:669\u001b[39m, in \u001b[36mApply._apply_str\u001b[39m\u001b[34m(self, obj, func, *args, **kwargs)\u001b[39m\n\u001b[32m    667\u001b[39m f = \u001b[38;5;28mgetattr\u001b[39m(obj, func)\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2378\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2372\u001b[39m         grouped_mean,\n\u001b[32m   2373\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2374\u001b[39m         engine_kwargs,\n\u001b[32m   2375\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2376\u001b[39m     )\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   1926\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1929\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1930\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   1931\u001b[39m out = \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1431\u001b[39m, in \u001b[36mBlockManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1429\u001b[39m             result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m   1430\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m         applied = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1432\u001b[39m         result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m   1434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_blocks) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:366\u001b[39m, in \u001b[36mBlock.apply\u001b[39m\u001b[34m(self, func, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, **kwargs) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    362\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    one\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     result = maybe_coerce_values(result)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._split_op_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1905\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1903\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34marray_func\u001b[39m(values: ArrayLike) -> ArrayLike:\n\u001b[32m   1904\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1905\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maggregate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1913\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m   1914\u001b[39m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[32m   1915\u001b[39m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[32m   1918\u001b[39m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[32m   1919\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33many\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:815\u001b[39m, in \u001b[36mBaseGrouper._cython_operation\u001b[39m\u001b[34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[39m\n\u001b[32m    813\u001b[39m ids, _, _ = \u001b[38;5;28mself\u001b[39m.group_info\n\u001b[32m    814\u001b[39m ngroups = \u001b[38;5;28mself\u001b[39m.ngroups\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcy_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:534\u001b[39m, in \u001b[36mWrappedCythonOp.cython_operation\u001b[39m\u001b[34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np.ndarray):\n\u001b[32m    524\u001b[39m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values._groupby_op(\n\u001b[32m    526\u001b[39m         how=\u001b[38;5;28mself\u001b[39m.how,\n\u001b[32m    527\u001b[39m         has_dropped_na=\u001b[38;5;28mself\u001b[39m.has_dropped_na,\n\u001b[32m   (...)\u001b[39m\u001b[32m    531\u001b[39m         **kwargs,\n\u001b[32m    532\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_op_ndim_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:338\u001b[39m, in \u001b[36mWrappedCythonOp._cython_op_ndim_compat\u001b[39m\u001b[34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# otherwise we have OHLC\u001b[39;00m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.T\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_cython_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:403\u001b[39m, in \u001b[36mWrappedCythonOp._call_cython_op\u001b[39m\u001b[34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m counts = np.zeros(ngroups, dtype=np.int64)\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_datetimelike\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_datetimelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33msem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mohlc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprod\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msem\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mgroupby.pyx:1045\u001b[39m, in \u001b[36mpandas._libs.groupby.group_mean\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 863. MiB for an array with shape (12566400, 9) and data type float64"
     ]
    }
   ],
   "source": [
    "# ✅ 4. Resample MAG/SWICS to 1-min — keep only numeric columns\n",
    "df_mag_numeric = df_mag.select_dtypes(include=[\"number\"])\n",
    "df_swics_numeric = df_swics.select_dtypes(include=[\"number\"])\n",
    "\n",
    "df_mag = df_mag_numeric.resample(\"1T\").mean().interpolate()\n",
    "df_swics = df_swics_numeric.resample(\"1T\").mean().interpolate()\n",
    "\n",
    "\n",
    "# ✅ 5. Merge everything\n",
    "df = (\n",
    "    df_epam[[\"Electron_38-53\", \"Electron_175-315\", \"Proton_47-65\", \"Proton_112-187\"]]\n",
    "    .join(df_mag[[\"Bx\", \"By\", \"Bz\"]], how=\"inner\")\n",
    "    .join(df_sis[[\"Proton_>10MeV\"]], how=\"inner\")\n",
    "    .join(df_swics[[\"Proton_Density\", \"Bulk_Speed\", \"Ion_Temperature\"]], how=\"inner\")\n",
    ")\n",
    "\n",
    "# ✅ 6. Feature Engineering\n",
    "df[\"Bt\"] = np.sqrt(df[\"Bx\"]**2 + df[\"By\"]**2 + df[\"Bz\"]**2)\n",
    "df[\"T_expected\"] = 0.031 * df[\"Bulk_Speed\"]**1.6\n",
    "df[\"Temp_Ratio\"] = df[\"Ion_Temperature\"] / df[\"T_expected\"]\n",
    "\n",
    "# ✅ 7. CME Shock Detection\n",
    "def detect_shocks(df, window=10, dV_thresh=70, dNp_thresh=5, dBt_thresh=4):\n",
    "    V_diff  = df[\"Bulk_Speed\"].diff(window)\n",
    "    Np_diff = df[\"Proton_Density\"].diff(window)\n",
    "    Bt_diff = df[\"Bt\"].diff(window)\n",
    "\n",
    "    mask = (V_diff > dV_thresh) & (Np_diff > dNp_thresh) & (Bt_diff > dBt_thresh)\n",
    "    return df.index[mask.fillna(False)]\n",
    "\n",
    "shocks = detect_shocks(df)\n",
    "\n",
    "# ✅ 8. Magnetic Cloud Detection\n",
    "def detect_mag_clouds(df, shocks, hours=24):\n",
    "    clouds = []\n",
    "    for t in shocks:\n",
    "        window = df.loc[t : t + pd.Timedelta(hours=hours)]\n",
    "        if len(window) == 0:\n",
    "            continue\n",
    "        low_temp = (window[\"Temp_Ratio\"] < 0.5).sum() > 0.75 * len(window)\n",
    "        low_beta = (window[\"Proton_Density\"] * window[\"Ion_Temperature\"] < 2 * (window[\"Bt\"]**2)).sum() > 0.75 * len(window)\n",
    "        if low_temp and low_beta:\n",
    "            clouds.append((t, t + pd.Timedelta(hours=hours)))\n",
    "    return clouds\n",
    "\n",
    "clouds = detect_mag_clouds(df, shocks)\n",
    "\n",
    "# ✅ 9. Output Results\n",
    "print(\"\\n🔍 Detected CME Shock Times:\")\n",
    "for t in shocks:\n",
    "    print(t)\n",
    "\n",
    "print(\"\\n🌩️ Magnetic Cloud Intervals:\")\n",
    "for start, end in clouds:\n",
    "    print(f\"{start} → {end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
